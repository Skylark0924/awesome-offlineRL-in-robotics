# awesome-offlineRL-in-robotics

This repository is mainly about offline reinforcement learning methods. This is an ongoing project now, so keep an eye on it.

Related works are listed as follows:

> Note that some works are just pre-printed articles.

**[Comprehensive version README (with Authors & Figures)](./Comprehensive_readme.md)**

---

Content

- [awesome-offlineRL-in-robotics](#awesome-offlinerl-in-robotics)
  - [Survey](#survey)
  - [Workshop](#workshop)
  - [Benchmark](#benchmark)
  - [Methodology](#methodology)
    - [Model-free](#model-free)
    - [Model-based](#model-based)
  - [Applications in Real Robotics](#applications-in-real-robotics)

## Survey

1. [A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems](https://arxiv.org/pdf/2203.01387.pdf) arxiv 2022
1. [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/pdf/2005.01643.pdf) arxiv 2020
1. [An Optimistic Perspective on Offline Reinforcement Learning](http://proceedings.mlr.press/v119/agarwal20c/agarwal20c.pdf) PMLR 2020

## Workshop 



## Benchmark

1. [D4RL: Datasets for Deep Data-Driven Reinforcement Learning](https://arxiv.org/pdf/2004.07219.pdf) arxiv 2020 | [Github](https://github.com/rail-berkeley/d4rl) | [web](https://sites.google.com/view/d4rl/)



## Methodology

### Model-free

1. [A Minimalist Approach to Offline Reinforcement Learning](https://proceedings.neurips.cc/paper/2021/file/a8166da05c5a094f7dc03724b41886e5-Paper.pdf) NeurIPS 2021
2. [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/pdf/2106.01345.pdf) NeurIPS 2021 | [Web](https://sites.google.com/berkeley.edu/decision-transformer) [Github](https://github.com/kzl/decision-transformer)
3. [CQL: Conservative Q-Learning for Offline Reinforcement Learning](https://proceedings.neurips.cc/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf) NeurIPS 2020
4. 



### Model-based

1. [MBOP: Model-Based Offline Planning](https://arxiv.org/pdf/2008.05556.pdf) ICLR 2021
2. [MOPO: Model-based Offline Policy Optimization](https://proceedings.neurips.cc/paper/2020/file/a322852ce0df73e204b7e67cbbef0d0a-Paper.pdf) NeurIPS 2020
3. [MOReL : Model-Based Offline Reinforcement Learning](https://proceedings.neurips.cc/paper/2020/file/f7efa4f864ae9b88d43527f4b14f750f-Paper.pdf) NeurIPS 2020



## Applications in Real Robotics
