# awesome-offlineRL-in-robotics

This repository is mainly about offline reinforcement learning methods. This is an ongoing project now, so keep an eye on it.

Related works are listed as follows:

> Note that some works are just pre-printed articles.

**[Comprehensive version README (with Authors & Figures)](./Comprehensive_readme.md)**

---

Content

- [awesome-offlineRL-in-robotics](#awesome-offlinerl-in-robotics)
  - [Survey](#survey)
  - [Workshop](#workshop)
  - [Benchmark](#benchmark)
  - [Methodology](#methodology)
    - [Model-free](#model-free)
    - [Model-based](#model-based)
    - [Combined with Imitation Learning](#combined-with-imitation-learning)
  - [Applications in Real Robotics](#applications-in-real-robotics)

## Survey

1. [A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems](https://arxiv.org/pdf/2203.01387.pdf) arxiv 2022
1. [Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems](https://arxiv.org/pdf/2005.01643.pdf) arxiv 2020
1. [An Optimistic Perspective on Offline Reinforcement Learning](http://proceedings.mlr.press/v119/agarwal20c/agarwal20c.pdf) ICML 2020

## Workshop 
1. [Imitation learning vs. offline reinforcement learning - Sergey Levine](https://www.youtube.com/watch?v=sVPm7zOrBxM)


## Benchmark

1. [D4RL: Datasets for Deep Data-Driven Reinforcement Learning](https://arxiv.org/pdf/2004.07219.pdf) arxiv 2020 | [web](https://sites.google.com/view/d4rl/) [Github](https://github.com/rail-berkeley/d4rl)



## Methodology
1. [When Should We Prefer Offline Reinforcement Learning Over Behavioral Cloning?](https://arxiv.org/pdf/2204.05618.pdf) ICLR 2022
2. [RvS: What is Essential for Offline RL via Supervised Learning?](https://arxiv.org/pdf/2112.10751.pdf) ICLR 2022 | [Note](./Notes/RvS.md)

### Model-free

1. [A Minimalist Approach to Offline Reinforcement Learning (TD3+BC)](https://proceedings.neurips.cc/paper/2021/file/a8166da05c5a094f7dc03724b41886e5-Paper.pdf) NeurIPS 2021
2. [Decision Transformer: Reinforcement Learning via Sequence Modeling](https://arxiv.org/pdf/2106.01345.pdf) NeurIPS 2021 | [Web](https://sites.google.com/berkeley.edu/decision-transformer) [Github](https://github.com/kzl/decision-transformer)
3. [Offline Reinforcement Learning with Fisher Divergence Critic Regularization (Fisher-BRC)](http://proceedings.mlr.press/v139/kostrikov21a/kostrikov21a.pdf) ICML 2021
4. [Conservative Q-Learning for Offline Reinforcement Learning (CQL)](https://proceedings.neurips.cc/paper/2020/file/0d2b2061826a5df3221116a5085a6052-Paper.pdf) NeurIPS 2020 | [Note](Notes/CQL.md)
5. [Behavior Regularized Offline Reinforcement Learning (BRAC)](https://arxiv.org/pdf/1911.11361.pdf) arxiv 2019
6. [Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction (BEAR)](https://arxiv.org/pdf/1906.00949.pdf) NeurIPS 2019
7. [Off-Policy Deep Reinforcement Learning without Exploration (BCQ)](https://arxiv.org/pdf/1812.02900.pdf) ICML 2019


### Model-based

1. [Model-Based Offline Planning (MBOP)](https://arxiv.org/pdf/2008.05556.pdf) ICLR 2021
2. [MOPO: Model-based Offline Policy Optimization](https://proceedings.neurips.cc/paper/2020/file/a322852ce0df73e204b7e67cbbef0d0a-Paper.pdf) NeurIPS 2020
3. [MOReL: Model-Based Offline Reinforcement Learning](https://proceedings.neurips.cc/paper/2020/file/f7efa4f864ae9b88d43527f4b14f750f-Paper.pdf) NeurIPS 2020


### Combined with Imitation Learning
1. [Rethinking Goal-conditioned Supervised Learning and Its Connection to Offline RL](https://arxiv.org/pdf/2202.04478.pdf) ICLR 2022
2. [Reinforcement Learning as One Big Sequence Modeling Problem (Trajectory Transformer)](https://openreview.net/pdf?id=AfDCOISXx1T) NeurIPS 2021
3. [Deep imitative models for flexible inference, planning, and control](https://arxiv.org/pdf/1810.06544.pdf)


## Applications in Real Robotics
